{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sound Classification for the Deaf\n",
        "\n",
        "Sound is essential in the daily lives of all living organisms. It tells us about the environment, its characteristics, people, places, and movements in ways that visuals cannot. In today's world, various types of sound are present in the environment, and it is necessary to classify useful sounds and noise. The various types of sounds produced in urban areas are considered for classification. This classified sound can be especially useful for hearing-impaired people who need to identify different types of sounds and react appropriately. The majority of hearing loss is caused by inner ear or nerve damage. A variety of factors cause the damage. It could be due to congenital defects, diseases, injury, exposure to loud noise for a long period of time, and age-related wear and tear. Among the above-stated reasons, only a few cases can be resolved using the Hearing Aid. The rest have to live with the defect, as there hasnâ€™t been any significant improvement in this field. Thus the proposed Sound Classification for Hearing Impaired people can help classify the different sounds and stay connected to the happenings of the environment. \n"
      ],
      "metadata": {
        "id": "TKZjlKpNFWJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EouDH4ewdfEM",
        "outputId": "89fc4285-448f-4581-fafa-229073d01907"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/Datasets/Deep_Learning"
      ],
      "metadata": {
        "id": "xe1FBUJ8eLp-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the Libraries"
      ],
      "metadata": {
        "id": "MdIhupkRKm9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#for loading and visualizing audio files\n",
        "import librosa\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "#To play audio\n",
        "import IPython.display as ipd\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Embedding, Flatten, Bidirectional, BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.applications import inception_v3\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:46.088378Z",
          "iopub.execute_input": "2022-11-20T04:52:46.089066Z",
          "iopub.status.idle": "2022-11-20T04:52:55.940441Z",
          "shell.execute_reply.started": "2022-11-20T04:52:46.088980Z",
          "shell.execute_reply": "2022-11-20T04:52:55.939132Z"
        },
        "trusted": true,
        "id": "QkxWZkGSaBNp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_csv = '/content/drive/MyDrive/Datasets/Deep_Learning/esc50.csv'\n",
        "audio_fpath = \"/content/drive/MyDrive/Datasets/Deep_Learning/audio/\""
      ],
      "metadata": {
        "id": "lz7LYRefdy67"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a fucntion to perform Audio Augmentation\n",
        "\n",
        "\n",
        "*   Add Noise\n",
        "*   Shift Audio\n",
        "*   Stretch Audio\n",
        "\n"
      ],
      "metadata": {
        "id": "CXgnv_UrKwjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioAugmentation:\n",
        "    \n",
        "    def read_audio_file(self, file_path):\n",
        "        input_length = 220500\n",
        "        data = librosa.load(file_path)[0]\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else:\n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data\n",
        "    \n",
        "    def add_noise(self, data):\n",
        "        noise = np.random.randn(len(data))\n",
        "        data_noise = data + 0.005 * noise\n",
        "        return data_noise\n",
        "    \n",
        "    def shift(self, data):\n",
        "        return np.roll(data, 22050)\n",
        "    \n",
        "    def stretch(self, data, rate=1):\n",
        "        input_length = 220500\n",
        "        data = librosa.effects.time_stretch(data, rate)\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else:\n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data\n",
        "\n",
        "    def write_audio_file(self, file, data, sample_rate=44100):\n",
        "        librosa.output.write_wav(file, data, sample_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:55.942557Z",
          "iopub.execute_input": "2022-11-20T04:52:55.943640Z",
          "iopub.status.idle": "2022-11-20T04:52:55.963178Z",
          "shell.execute_reply.started": "2022-11-20T04:52:55.943607Z",
          "shell.execute_reply": "2022-11-20T04:52:55.961867Z"
        },
        "trusted": true,
        "id": "nU0AIBqZaBNt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting WAV audio to Mel spectrograms"
      ],
      "metadata": {
        "id": "0T_S-fakLfti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(dirname):\n",
        "    if os.path.exists(dirname):\n",
        "        pass\n",
        "    else:\n",
        "        os.makedirs(dirname)\n",
        "        \n",
        "def wav2mel(path, clip, output, sample_rate=44100):\n",
        "    x, sr = librosa.load(path+clip, sr=sample_rate)\n",
        "    sgram=librosa.stft(x)\n",
        "    sgram_mag, _ = librosa.magphase(sgram)\n",
        "    \n",
        "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=sr)\n",
        "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
        "    librosa.display.specshow(mel_sgram, sr=sr, x_axis='time', y_axis='mel')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.savefig(output)\n",
        "    plt.clf()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:55.965420Z",
          "iopub.execute_input": "2022-11-20T04:52:55.966192Z",
          "iopub.status.idle": "2022-11-20T04:52:55.984979Z",
          "shell.execute_reply.started": "2022-11-20T04:52:55.966153Z",
          "shell.execute_reply": "2022-11-20T04:52:55.983840Z"
        },
        "trusted": true,
        "id": "VUrkGnNJaBNu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_clips = os.listdir(audio_fpath)\n",
        "print(\"No. of .wav files in audio folder = \",len(audio_clips))\n",
        "df = pd.read_csv(label_csv)\n",
        "\n",
        "print(df.head())\n",
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:55.988516Z",
          "iopub.execute_input": "2022-11-20T04:52:55.988896Z",
          "iopub.status.idle": "2022-11-20T04:52:56.105827Z",
          "shell.execute_reply.started": "2022-11-20T04:52:55.988861Z",
          "shell.execute_reply": "2022-11-20T04:52:56.104790Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZUF7WZtaBNv",
        "outputId": "fb9ae4db-e166-45df-821b-fc2049ee5a5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of .wav files in audio folder =  2002\n",
            "            filename  fold  target        category  esc10  src_file take\n",
            "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
            "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
            "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
            "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
            "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, sr = librosa.load(audio_fpath+audio_clips[0], sr=44100)\n",
        "print(type(x), type(sr))\n",
        "print(x.shape, sr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:56.107461Z",
          "iopub.execute_input": "2022-11-20T04:52:56.108178Z",
          "iopub.status.idle": "2022-11-20T04:52:56.918859Z",
          "shell.execute_reply.started": "2022-11-20T04:52:56.108138Z",
          "shell.execute_reply": "2022-11-20T04:52:56.917093Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5twm81paBNw",
        "outputId": "32b87ec3-648f-4b50-a8c9-12f23303737a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'int'>\n",
            "(220500,) 44100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = librosa.feature.mfcc(y=x, sr = 44100)\n",
        "print(feature.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:56.921661Z",
          "iopub.execute_input": "2022-11-20T04:52:56.922528Z",
          "iopub.status.idle": "2022-11-20T04:52:56.968176Z",
          "shell.execute_reply.started": "2022-11-20T04:52:56.922480Z",
          "shell.execute_reply": "2022-11-20T04:52:56.966714Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXiWHwZaBNw",
        "outputId": "c5463cc7-019a-4c5a-a2cb-6b6bd8db30de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 431)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa = AudioAugmentation()\n",
        "extracted_data = []\n",
        "for index, row in tqdm(df.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(audio_fpath),str(row[\"filename\"]))\n",
        "    class_labels = row['category']\n",
        "    y, sr = librosa.load(file_name, sr=44100)\n",
        "    for i in range(8):\n",
        "        if i == 1 or i >3:\n",
        "            y = aa.add_noise(y)\n",
        "        if i%3 == 2 or i == 7:\n",
        "            y = aa.shift(y)\n",
        "        if i%3 == 0 or i == 7:\n",
        "            y = aa.stretch(y, rate=1.25)\n",
        "        feature = librosa.feature.mfcc(y=y, sr=sr)\n",
        "        scaled_feature = np.mean(feature.T,axis=0)\n",
        "        extracted_data.append([scaled_feature, class_labels])\n",
        "np.array(extracted_data).shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-11-20T04:52:56.974426Z",
          "iopub.execute_input": "2022-11-20T04:52:56.977578Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRT4GKZGaBNx",
        "outputId": "9fb5eadb-97eb-4ec8-d6cd-e74e140ca9b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [27:48,  1.20it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = pd.DataFrame(extracted_data, columns=['feature','class'])\n",
        "\n",
        "print(feature_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRBua5PnaBNy",
        "outputId": "27d6f353-c811-4fa3-f405-ec87bcde560e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             feature class\n",
            "0  [-632.056, 6.9280477, -5.63157, -3.5181608, -2...   dog\n",
            "1  [-347.0140501621845, -2.3466943466216255, -3.4...   dog\n",
            "2  [-346.99730532163295, -2.3201645024259503, -3....   dog\n",
            "3  [-444.0913414305589, -2.4582368844355416, -3.2...   dog\n",
            "4  [-334.505736931939, -3.838682366879073, -3.241...   dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(feature_df['feature'].tolist())\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI5BkF1taBNy",
        "outputId": "b5942895-cb94-4ff0-abfc-8302049e060a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = np.array(feature_df['class'].tolist())"
      ],
      "metadata": {
        "trusted": true,
        "id": "XTKQpF_saBNz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = pd.get_dummies(target)\n",
        "print(y_new.shape)\n",
        "y_new.head()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9Srvfl6jaBNz",
        "outputId": "fca262a0-e9b8-4f7e-fde3-37b44f4eed07"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16000, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   airplane  breathing  brushing_teeth  can_opening  car_horn  cat  chainsaw  \\\n",
              "0         0          0               0            0         0    0         0   \n",
              "1         0          0               0            0         0    0         0   \n",
              "2         0          0               0            0         0    0         0   \n",
              "3         0          0               0            0         0    0         0   \n",
              "4         0          0               0            0         0    0         0   \n",
              "\n",
              "   chirping_birds  church_bells  clapping  ...  siren  sneezing  snoring  \\\n",
              "0               0             0         0  ...      0         0        0   \n",
              "1               0             0         0  ...      0         0        0   \n",
              "2               0             0         0  ...      0         0        0   \n",
              "3               0             0         0  ...      0         0        0   \n",
              "4               0             0         0  ...      0         0        0   \n",
              "\n",
              "   thunderstorm  toilet_flush  train  vacuum_cleaner  washing_machine  \\\n",
              "0             0             0      0               0                0   \n",
              "1             0             0      0               0                0   \n",
              "2             0             0      0               0                0   \n",
              "3             0             0      0               0                0   \n",
              "4             0             0      0               0                0   \n",
              "\n",
              "   water_drops  wind  \n",
              "0            0     0  \n",
              "1            0     0  \n",
              "2            0     0  \n",
              "3            0     0  \n",
              "4            0     0  \n",
              "\n",
              "[5 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9066ae09-f4c2-4195-97c2-fae10a6ce8a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airplane</th>\n",
              "      <th>breathing</th>\n",
              "      <th>brushing_teeth</th>\n",
              "      <th>can_opening</th>\n",
              "      <th>car_horn</th>\n",
              "      <th>cat</th>\n",
              "      <th>chainsaw</th>\n",
              "      <th>chirping_birds</th>\n",
              "      <th>church_bells</th>\n",
              "      <th>clapping</th>\n",
              "      <th>...</th>\n",
              "      <th>siren</th>\n",
              "      <th>sneezing</th>\n",
              "      <th>snoring</th>\n",
              "      <th>thunderstorm</th>\n",
              "      <th>toilet_flush</th>\n",
              "      <th>train</th>\n",
              "      <th>vacuum_cleaner</th>\n",
              "      <th>washing_machine</th>\n",
              "      <th>water_drops</th>\n",
              "      <th>wind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9066ae09-f4c2-4195-97c2-fae10a6ce8a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9066ae09-f4c2-4195-97c2-fae10a6ce8a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9066ae09-f4c2-4195-97c2-fae10a6ce8a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "liHixbA6L62z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y_new, test_size=0.1, random_state=15)\n",
        "print(str(X_train.shape)+ ', ' + str(X_test.shape))\n",
        "inp = (1, 20)\n",
        "np.array(X_train).reshape(14400, 1, 20)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30kB5OPDaBNz",
        "outputId": "7f08a718-a61f-461a-9c91-f6f239daea49"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14400, 20), (1600, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-2.68931702e+02,  1.08840683e+02, -2.64278297e+01, ...,\n",
              "         -2.29460672e-01,  1.59656227e+00, -1.96956539e+00]],\n",
              "\n",
              "       [[-1.97485795e+02,  4.95122940e+01, -3.69908317e+01, ...,\n",
              "         -9.09766974e-01,  7.34863632e+00,  5.75032249e-01]],\n",
              "\n",
              "       [[-4.34523947e+02, -2.66062053e+00, -2.51423299e+00, ...,\n",
              "          8.16617681e-01,  2.08738926e-01, -2.65217355e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-3.05396967e+02,  1.41219500e+01, -8.39233621e+00, ...,\n",
              "          6.36336461e+00,  7.85116085e+00,  4.99926772e+00]],\n",
              "\n",
              "       [[-2.85572299e+02,  1.97179076e+01,  5.38035463e+00, ...,\n",
              "          3.21608591e-01,  2.15903958e+00,  4.27415025e+00]],\n",
              "\n",
              "       [[-6.11604065e+02,  7.95887222e+01,  1.48437929e+00, ...,\n",
              "          1.41405433e-01,  6.48340082e+00, -2.98140585e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(X_train).reshape(14400,1,20)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLUF6gcpaBN0",
        "outputId": "dc30ea21-e29f-4968-f8b5-29d5f5155131"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-2.68931702e+02,  1.08840683e+02, -2.64278297e+01, ...,\n",
              "         -2.29460672e-01,  1.59656227e+00, -1.96956539e+00]],\n",
              "\n",
              "       [[-1.97485795e+02,  4.95122940e+01, -3.69908317e+01, ...,\n",
              "         -9.09766974e-01,  7.34863632e+00,  5.75032249e-01]],\n",
              "\n",
              "       [[-4.34523947e+02, -2.66062053e+00, -2.51423299e+00, ...,\n",
              "          8.16617681e-01,  2.08738926e-01, -2.65217355e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-3.05396967e+02,  1.41219500e+01, -8.39233621e+00, ...,\n",
              "          6.36336461e+00,  7.85116085e+00,  4.99926772e+00]],\n",
              "\n",
              "       [[-2.85572299e+02,  1.97179076e+01,  5.38035463e+00, ...,\n",
              "          3.21608591e-01,  2.15903958e+00,  4.27415025e+00]],\n",
              "\n",
              "       [[-6.11604065e+02,  7.95887222e+01,  1.48437929e+00, ...,\n",
              "          1.41405433e-01,  6.48340082e+00, -2.98140585e-01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Train-Test Split"
      ],
      "metadata": {
        "id": "QcxtzB1lL_Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape = (1,20)))\n",
        "model.add(Bidirectional(LSTM(1024, return_sequences = True, recurrent_dropout = 0.1)))\n",
        "model.add(Flatten())\n",
        "# Gave a Testing accuracy of 75 so removing the following two layers\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='softmax'))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "                  optimizer=adam,\n",
        "                  metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zRyABZxaBN0",
        "outputId": "bf55e907-d4b9-4d77-b20d-bd3284380d99"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 1, 2048)          8560640   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                102450    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,663,090\n",
            "Trainable params: 8,663,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Fit the Model"
      ],
      "metadata": {
        "id": "nI9UhJV4MGnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    restore_best_weights=True, \n",
        "    patience=30, min_delta = 0.001\n",
        ")\n",
        "lrr = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                        patience=3, \n",
        "                        verbose=1, \n",
        "                        factor=0.5,\n",
        "                        min_lr=0.00001)\n",
        "\n",
        "history=model.fit(np.array(X_train).reshape(14400, 1, 20),\n",
        "        np.array(y_train),\n",
        "        epochs=500,\n",
        "        callbacks = [lrr],\n",
        "        batch_size = 100,\n",
        "        validation_data = (np.array(X_test).reshape(1600,1,20),\n",
        "                            np.array(y_test))\n",
        "                           )"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9f7WmnIaBN0",
        "outputId": "73bdbd58-2b07-4caf-fbff-21f387227415"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "144/144 [==============================] - 5s 15ms/step - loss: 2.8771 - accuracy: 0.2212 - val_loss: 2.5077 - val_accuracy: 0.2800 - lr: 0.0020\n",
            "Epoch 2/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 2.3048 - accuracy: 0.3505 - val_loss: 2.1567 - val_accuracy: 0.3837 - lr: 0.0020\n",
            "Epoch 3/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 2.0091 - accuracy: 0.4244 - val_loss: 1.9971 - val_accuracy: 0.4325 - lr: 0.0020\n",
            "Epoch 4/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 1.8031 - accuracy: 0.4839 - val_loss: 1.8982 - val_accuracy: 0.4519 - lr: 0.0020\n",
            "Epoch 5/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.6364 - accuracy: 0.5351 - val_loss: 1.7414 - val_accuracy: 0.4938 - lr: 0.0020\n",
            "Epoch 6/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.4907 - accuracy: 0.5763 - val_loss: 1.5721 - val_accuracy: 0.5400 - lr: 0.0020\n",
            "Epoch 7/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.3766 - accuracy: 0.6113 - val_loss: 1.4883 - val_accuracy: 0.5725 - lr: 0.0020\n",
            "Epoch 8/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.2788 - accuracy: 0.6394 - val_loss: 1.4347 - val_accuracy: 0.5938 - lr: 0.0020\n",
            "Epoch 9/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.1878 - accuracy: 0.6642 - val_loss: 1.3231 - val_accuracy: 0.6219 - lr: 0.0020\n",
            "Epoch 10/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.1013 - accuracy: 0.6880 - val_loss: 1.2603 - val_accuracy: 0.6419 - lr: 0.0020\n",
            "Epoch 11/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 1.0516 - accuracy: 0.7036 - val_loss: 1.2065 - val_accuracy: 0.6650 - lr: 0.0020\n",
            "Epoch 12/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.9618 - accuracy: 0.7255 - val_loss: 1.1914 - val_accuracy: 0.6619 - lr: 0.0020\n",
            "Epoch 13/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.9171 - accuracy: 0.7389 - val_loss: 1.0770 - val_accuracy: 0.6888 - lr: 0.0020\n",
            "Epoch 14/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.8762 - accuracy: 0.7522 - val_loss: 1.0681 - val_accuracy: 0.6944 - lr: 0.0020\n",
            "Epoch 15/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.8175 - accuracy: 0.7717 - val_loss: 1.0441 - val_accuracy: 0.7088 - lr: 0.0020\n",
            "Epoch 16/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.7851 - accuracy: 0.7796 - val_loss: 1.0249 - val_accuracy: 0.7075 - lr: 0.0020\n",
            "Epoch 17/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.7461 - accuracy: 0.7890 - val_loss: 0.9539 - val_accuracy: 0.7181 - lr: 0.0020\n",
            "Epoch 18/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.7153 - accuracy: 0.7983 - val_loss: 0.9553 - val_accuracy: 0.7312 - lr: 0.0020\n",
            "Epoch 19/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.6891 - accuracy: 0.8075 - val_loss: 0.9073 - val_accuracy: 0.7431 - lr: 0.0020\n",
            "Epoch 20/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.6575 - accuracy: 0.8115 - val_loss: 0.8762 - val_accuracy: 0.7437 - lr: 0.0020\n",
            "Epoch 21/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.6470 - accuracy: 0.8173 - val_loss: 0.8944 - val_accuracy: 0.7469 - lr: 0.0020\n",
            "Epoch 22/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.6231 - accuracy: 0.8256 - val_loss: 0.8775 - val_accuracy: 0.7412 - lr: 0.0020\n",
            "Epoch 23/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.5909 - accuracy: 0.8317 - val_loss: 0.8387 - val_accuracy: 0.7569 - lr: 0.0020\n",
            "Epoch 24/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.5634 - accuracy: 0.8422 - val_loss: 0.7948 - val_accuracy: 0.7738 - lr: 0.0020\n",
            "Epoch 25/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.5483 - accuracy: 0.8451 - val_loss: 0.8488 - val_accuracy: 0.7563 - lr: 0.0020\n",
            "Epoch 26/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.5316 - accuracy: 0.8500 - val_loss: 0.8595 - val_accuracy: 0.7613 - lr: 0.0020\n",
            "Epoch 27/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.5133 - accuracy: 0.8539 - val_loss: 0.7520 - val_accuracy: 0.7825 - lr: 0.0020\n",
            "Epoch 28/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.5008 - accuracy: 0.8587 - val_loss: 0.7492 - val_accuracy: 0.7831 - lr: 0.0020\n",
            "Epoch 29/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.4843 - accuracy: 0.8633 - val_loss: 0.7091 - val_accuracy: 0.8025 - lr: 0.0020\n",
            "Epoch 30/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.4576 - accuracy: 0.8702 - val_loss: 0.7038 - val_accuracy: 0.8037 - lr: 0.0020\n",
            "Epoch 31/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.4578 - accuracy: 0.8673 - val_loss: 0.7214 - val_accuracy: 0.7981 - lr: 0.0020\n",
            "Epoch 32/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.4680 - accuracy: 0.8673 - val_loss: 0.7062 - val_accuracy: 0.7862 - lr: 0.0020\n",
            "Epoch 33/500\n",
            "144/144 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8724\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.4532 - accuracy: 0.8724 - val_loss: 0.7002 - val_accuracy: 0.7919 - lr: 0.0020\n",
            "Epoch 34/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.3443 - accuracy: 0.9025 - val_loss: 0.5772 - val_accuracy: 0.8344 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.3108 - accuracy: 0.9162 - val_loss: 0.5742 - val_accuracy: 0.8331 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.3023 - accuracy: 0.9190 - val_loss: 0.5910 - val_accuracy: 0.8275 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "140/144 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.9162\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.2980 - accuracy: 0.9169 - val_loss: 0.5674 - val_accuracy: 0.8344 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2539 - accuracy: 0.9351 - val_loss: 0.5114 - val_accuracy: 0.8544 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.2454 - accuracy: 0.9356 - val_loss: 0.5045 - val_accuracy: 0.8562 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.2420 - accuracy: 0.9359 - val_loss: 0.4980 - val_accuracy: 0.8575 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2391 - accuracy: 0.9378 - val_loss: 0.4957 - val_accuracy: 0.8650 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2358 - accuracy: 0.9394 - val_loss: 0.4978 - val_accuracy: 0.8631 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2327 - accuracy: 0.9395 - val_loss: 0.5083 - val_accuracy: 0.8569 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "144/144 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9403\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2276 - accuracy: 0.9403 - val_loss: 0.4833 - val_accuracy: 0.8581 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2087 - accuracy: 0.9479 - val_loss: 0.4647 - val_accuracy: 0.8712 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2047 - accuracy: 0.9508 - val_loss: 0.4690 - val_accuracy: 0.8706 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2019 - accuracy: 0.9502 - val_loss: 0.4693 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "141/144 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9521\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.9524 - val_loss: 0.4594 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1913 - accuracy: 0.9547 - val_loss: 0.4506 - val_accuracy: 0.8775 - lr: 1.2500e-04\n",
            "Epoch 50/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1888 - accuracy: 0.9553 - val_loss: 0.4528 - val_accuracy: 0.8731 - lr: 1.2500e-04\n",
            "Epoch 51/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1876 - accuracy: 0.9571 - val_loss: 0.4487 - val_accuracy: 0.8756 - lr: 1.2500e-04\n",
            "Epoch 52/500\n",
            "144/144 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.9564\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1866 - accuracy: 0.9564 - val_loss: 0.4500 - val_accuracy: 0.8744 - lr: 1.2500e-04\n",
            "Epoch 53/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1815 - accuracy: 0.9588 - val_loss: 0.4426 - val_accuracy: 0.8737 - lr: 6.2500e-05\n",
            "Epoch 54/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1813 - accuracy: 0.9584 - val_loss: 0.4430 - val_accuracy: 0.8775 - lr: 6.2500e-05\n",
            "Epoch 55/500\n",
            "139/144 [===========================>..] - ETA: 0s - loss: 0.1811 - accuracy: 0.9592\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9592 - val_loss: 0.4437 - val_accuracy: 0.8775 - lr: 6.2500e-05\n",
            "Epoch 56/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1776 - accuracy: 0.9599 - val_loss: 0.4397 - val_accuracy: 0.8769 - lr: 3.1250e-05\n",
            "Epoch 57/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1771 - accuracy: 0.9610 - val_loss: 0.4403 - val_accuracy: 0.8781 - lr: 3.1250e-05\n",
            "Epoch 58/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1769 - accuracy: 0.9609 - val_loss: 0.4407 - val_accuracy: 0.8756 - lr: 3.1250e-05\n",
            "Epoch 59/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1768 - accuracy: 0.9604 - val_loss: 0.4396 - val_accuracy: 0.8769 - lr: 3.1250e-05\n",
            "Epoch 60/500\n",
            "144/144 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9611\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1765 - accuracy: 0.9611 - val_loss: 0.4396 - val_accuracy: 0.8769 - lr: 3.1250e-05\n",
            "Epoch 61/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1748 - accuracy: 0.9620 - val_loss: 0.4391 - val_accuracy: 0.8769 - lr: 1.5625e-05\n",
            "Epoch 62/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1747 - accuracy: 0.9615 - val_loss: 0.4386 - val_accuracy: 0.8744 - lr: 1.5625e-05\n",
            "Epoch 63/500\n",
            "140/144 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9619\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1745 - accuracy: 0.9619 - val_loss: 0.4390 - val_accuracy: 0.8756 - lr: 1.5625e-05\n",
            "Epoch 64/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1738 - accuracy: 0.9615 - val_loss: 0.4387 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 65/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1736 - accuracy: 0.9619 - val_loss: 0.4384 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 66/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1736 - accuracy: 0.9617 - val_loss: 0.4383 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 67/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1735 - accuracy: 0.9613 - val_loss: 0.4382 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 68/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9627 - val_loss: 0.4380 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 69/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.9619 - val_loss: 0.4382 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 70/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1733 - accuracy: 0.9615 - val_loss: 0.4380 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 71/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.9621 - val_loss: 0.4381 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 72/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1730 - accuracy: 0.9620 - val_loss: 0.4383 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 73/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1730 - accuracy: 0.9617 - val_loss: 0.4375 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 74/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1728 - accuracy: 0.9616 - val_loss: 0.4379 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 75/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1727 - accuracy: 0.9619 - val_loss: 0.4376 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 76/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1727 - accuracy: 0.9625 - val_loss: 0.4376 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 77/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1726 - accuracy: 0.9618 - val_loss: 0.4374 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 78/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9619 - val_loss: 0.4371 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 79/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9624 - val_loss: 0.4375 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 80/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1723 - accuracy: 0.9617 - val_loss: 0.4371 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 81/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1722 - accuracy: 0.9620 - val_loss: 0.4370 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 82/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.9620 - val_loss: 0.4371 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 83/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1720 - accuracy: 0.9624 - val_loss: 0.4369 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 84/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1719 - accuracy: 0.9622 - val_loss: 0.4367 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 85/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.9624 - val_loss: 0.4372 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 86/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9621 - val_loss: 0.4365 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 87/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1716 - accuracy: 0.9624 - val_loss: 0.4366 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 88/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9629 - val_loss: 0.4363 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 89/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1714 - accuracy: 0.9622 - val_loss: 0.4366 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 90/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9622 - val_loss: 0.4362 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 91/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9628 - val_loss: 0.4363 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 92/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9619 - val_loss: 0.4363 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 93/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1710 - accuracy: 0.9626 - val_loss: 0.4356 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 94/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9626 - val_loss: 0.4355 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 95/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1708 - accuracy: 0.9629 - val_loss: 0.4351 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 96/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1707 - accuracy: 0.9621 - val_loss: 0.4354 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 97/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1705 - accuracy: 0.9626 - val_loss: 0.4355 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 98/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1704 - accuracy: 0.9628 - val_loss: 0.4354 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 99/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1704 - accuracy: 0.9625 - val_loss: 0.4349 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 100/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1703 - accuracy: 0.9622 - val_loss: 0.4348 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 101/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1702 - accuracy: 0.9626 - val_loss: 0.4348 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 102/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.9624 - val_loss: 0.4350 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 103/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9631 - val_loss: 0.4347 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 104/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9629 - val_loss: 0.4349 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 105/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1698 - accuracy: 0.9625 - val_loss: 0.4343 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 106/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9629 - val_loss: 0.4343 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 107/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1695 - accuracy: 0.9626 - val_loss: 0.4343 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 108/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1694 - accuracy: 0.9633 - val_loss: 0.4341 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 109/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1694 - accuracy: 0.9633 - val_loss: 0.4340 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 110/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1693 - accuracy: 0.9632 - val_loss: 0.4337 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 111/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1692 - accuracy: 0.9631 - val_loss: 0.4336 - val_accuracy: 0.8756 - lr: 1.0000e-05\n",
            "Epoch 112/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1691 - accuracy: 0.9631 - val_loss: 0.4334 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 113/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1690 - accuracy: 0.9627 - val_loss: 0.4334 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 114/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1689 - accuracy: 0.9629 - val_loss: 0.4334 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 115/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1688 - accuracy: 0.9630 - val_loss: 0.4332 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 116/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1687 - accuracy: 0.9636 - val_loss: 0.4330 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 117/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1686 - accuracy: 0.9634 - val_loss: 0.4326 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 118/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1685 - accuracy: 0.9633 - val_loss: 0.4330 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 119/500\n",
            "144/144 [==============================] - 1s 9ms/step - loss: 0.1684 - accuracy: 0.9636 - val_loss: 0.4331 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 120/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1684 - accuracy: 0.9627 - val_loss: 0.4327 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 121/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1682 - accuracy: 0.9633 - val_loss: 0.4328 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 122/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1681 - accuracy: 0.9636 - val_loss: 0.4322 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 123/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9630 - val_loss: 0.4325 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 124/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9629 - val_loss: 0.4320 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 125/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1678 - accuracy: 0.9633 - val_loss: 0.4319 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 126/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1677 - accuracy: 0.9628 - val_loss: 0.4317 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 127/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1676 - accuracy: 0.9635 - val_loss: 0.4320 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 128/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1675 - accuracy: 0.9633 - val_loss: 0.4318 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 129/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1674 - accuracy: 0.9628 - val_loss: 0.4316 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 130/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1673 - accuracy: 0.9636 - val_loss: 0.4316 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 131/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1672 - accuracy: 0.9635 - val_loss: 0.4310 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 132/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1671 - accuracy: 0.9630 - val_loss: 0.4308 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 133/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1670 - accuracy: 0.9631 - val_loss: 0.4309 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 134/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1670 - accuracy: 0.9633 - val_loss: 0.4308 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 135/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1668 - accuracy: 0.9638 - val_loss: 0.4308 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 136/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1668 - accuracy: 0.9636 - val_loss: 0.4305 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 137/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1666 - accuracy: 0.9628 - val_loss: 0.4304 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 138/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1665 - accuracy: 0.9634 - val_loss: 0.4309 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 139/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1665 - accuracy: 0.9641 - val_loss: 0.4303 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 140/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1664 - accuracy: 0.9635 - val_loss: 0.4304 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 141/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1662 - accuracy: 0.9637 - val_loss: 0.4298 - val_accuracy: 0.8781 - lr: 1.0000e-05\n",
            "Epoch 142/500\n",
            "144/144 [==============================] - 2s 17ms/step - loss: 0.1661 - accuracy: 0.9638 - val_loss: 0.4299 - val_accuracy: 0.8763 - lr: 1.0000e-05\n",
            "Epoch 143/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1660 - accuracy: 0.9638 - val_loss: 0.4299 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 144/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1659 - accuracy: 0.9638 - val_loss: 0.4297 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 145/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1658 - accuracy: 0.9637 - val_loss: 0.4296 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 146/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1658 - accuracy: 0.9637 - val_loss: 0.4294 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
            "Epoch 147/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1657 - accuracy: 0.9633 - val_loss: 0.4297 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 148/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1656 - accuracy: 0.9642 - val_loss: 0.4295 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 149/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1655 - accuracy: 0.9637 - val_loss: 0.4293 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 150/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1653 - accuracy: 0.9639 - val_loss: 0.4291 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 151/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1653 - accuracy: 0.9633 - val_loss: 0.4290 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 152/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1652 - accuracy: 0.9638 - val_loss: 0.4291 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 153/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1651 - accuracy: 0.9643 - val_loss: 0.4286 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 154/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1650 - accuracy: 0.9639 - val_loss: 0.4286 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 155/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1649 - accuracy: 0.9636 - val_loss: 0.4290 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 156/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1648 - accuracy: 0.9643 - val_loss: 0.4285 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 157/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1647 - accuracy: 0.9644 - val_loss: 0.4283 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 158/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9638 - val_loss: 0.4281 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 159/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1645 - accuracy: 0.9641 - val_loss: 0.4282 - val_accuracy: 0.8775 - lr: 1.0000e-05\n",
            "Epoch 160/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1644 - accuracy: 0.9640 - val_loss: 0.4284 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 161/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1643 - accuracy: 0.9641 - val_loss: 0.4279 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 162/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1642 - accuracy: 0.9640 - val_loss: 0.4277 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 163/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1641 - accuracy: 0.9642 - val_loss: 0.4276 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 164/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1639 - accuracy: 0.9640 - val_loss: 0.4275 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 165/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1640 - accuracy: 0.9637 - val_loss: 0.4274 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 166/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1638 - accuracy: 0.9644 - val_loss: 0.4273 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 167/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1637 - accuracy: 0.9644 - val_loss: 0.4272 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 168/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1636 - accuracy: 0.9643 - val_loss: 0.4272 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 169/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1634 - accuracy: 0.9643 - val_loss: 0.4267 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 170/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1635 - accuracy: 0.9638 - val_loss: 0.4269 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 171/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1633 - accuracy: 0.9641 - val_loss: 0.4268 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 172/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1632 - accuracy: 0.9649 - val_loss: 0.4272 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 173/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1631 - accuracy: 0.9645 - val_loss: 0.4266 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 174/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1630 - accuracy: 0.9644 - val_loss: 0.4267 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 175/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1630 - accuracy: 0.9646 - val_loss: 0.4268 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 176/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.9646 - val_loss: 0.4267 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 177/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.9645 - val_loss: 0.4262 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 178/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1626 - accuracy: 0.9644 - val_loss: 0.4263 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 179/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.9643 - val_loss: 0.4262 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 180/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1624 - accuracy: 0.9647 - val_loss: 0.4258 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 181/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1624 - accuracy: 0.9647 - val_loss: 0.4260 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 182/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1623 - accuracy: 0.9647 - val_loss: 0.4261 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 183/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1621 - accuracy: 0.9642 - val_loss: 0.4260 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 184/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1621 - accuracy: 0.9648 - val_loss: 0.4260 - val_accuracy: 0.8788 - lr: 1.0000e-05\n",
            "Epoch 185/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9643 - val_loss: 0.4257 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 186/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9648 - val_loss: 0.4258 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 187/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9643 - val_loss: 0.4258 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 188/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1616 - accuracy: 0.9653 - val_loss: 0.4255 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 189/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1616 - accuracy: 0.9649 - val_loss: 0.4252 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1616 - accuracy: 0.9653 - val_loss: 0.4251 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1614 - accuracy: 0.9649 - val_loss: 0.4249 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1613 - accuracy: 0.9653 - val_loss: 0.4245 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1611 - accuracy: 0.9653 - val_loss: 0.4248 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1611 - accuracy: 0.9647 - val_loss: 0.4248 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 195/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1611 - accuracy: 0.9650 - val_loss: 0.4247 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1610 - accuracy: 0.9656 - val_loss: 0.4247 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1608 - accuracy: 0.9649 - val_loss: 0.4244 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9651 - val_loss: 0.4240 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9651 - val_loss: 0.4240 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9650 - val_loss: 0.4240 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1604 - accuracy: 0.9653 - val_loss: 0.4239 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1604 - accuracy: 0.9656 - val_loss: 0.4238 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1603 - accuracy: 0.9658 - val_loss: 0.4236 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1602 - accuracy: 0.9651 - val_loss: 0.4236 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1601 - accuracy: 0.9655 - val_loss: 0.4238 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1600 - accuracy: 0.9652 - val_loss: 0.4233 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 207/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1600 - accuracy: 0.9653 - val_loss: 0.4234 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 208/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1598 - accuracy: 0.9653 - val_loss: 0.4234 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 209/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1597 - accuracy: 0.9658 - val_loss: 0.4230 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 210/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1596 - accuracy: 0.9656 - val_loss: 0.4234 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 211/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1596 - accuracy: 0.9654 - val_loss: 0.4231 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 212/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1595 - accuracy: 0.9656 - val_loss: 0.4233 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 213/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1594 - accuracy: 0.9657 - val_loss: 0.4229 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 214/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1593 - accuracy: 0.9657 - val_loss: 0.4227 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 215/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1592 - accuracy: 0.9655 - val_loss: 0.4227 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 216/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9656 - val_loss: 0.4227 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 217/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1590 - accuracy: 0.9653 - val_loss: 0.4227 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1589 - accuracy: 0.9658 - val_loss: 0.4227 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1588 - accuracy: 0.9658 - val_loss: 0.4227 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1587 - accuracy: 0.9653 - val_loss: 0.4225 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1587 - accuracy: 0.9656 - val_loss: 0.4223 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1585 - accuracy: 0.9658 - val_loss: 0.4223 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1584 - accuracy: 0.9658 - val_loss: 0.4226 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1584 - accuracy: 0.9658 - val_loss: 0.4224 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 225/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1582 - accuracy: 0.9658 - val_loss: 0.4222 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 226/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1582 - accuracy: 0.9658 - val_loss: 0.4221 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 227/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1581 - accuracy: 0.9665 - val_loss: 0.4219 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 228/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1580 - accuracy: 0.9662 - val_loss: 0.4218 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 229/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1579 - accuracy: 0.9659 - val_loss: 0.4216 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 230/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1578 - accuracy: 0.9661 - val_loss: 0.4219 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 231/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1577 - accuracy: 0.9660 - val_loss: 0.4216 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 232/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1576 - accuracy: 0.9660 - val_loss: 0.4218 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 233/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1575 - accuracy: 0.9660 - val_loss: 0.4217 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 234/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1574 - accuracy: 0.9658 - val_loss: 0.4214 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 235/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1574 - accuracy: 0.9655 - val_loss: 0.4213 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 236/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1573 - accuracy: 0.9661 - val_loss: 0.4216 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 237/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1572 - accuracy: 0.9663 - val_loss: 0.4215 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 238/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1571 - accuracy: 0.9657 - val_loss: 0.4212 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 239/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1571 - accuracy: 0.9660 - val_loss: 0.4211 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 240/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1570 - accuracy: 0.9664 - val_loss: 0.4211 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 241/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1569 - accuracy: 0.9662 - val_loss: 0.4212 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 242/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1567 - accuracy: 0.9664 - val_loss: 0.4212 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 243/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1567 - accuracy: 0.9663 - val_loss: 0.4209 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 244/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1566 - accuracy: 0.9667 - val_loss: 0.4208 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 245/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1565 - accuracy: 0.9662 - val_loss: 0.4205 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 246/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1564 - accuracy: 0.9663 - val_loss: 0.4205 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 247/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1563 - accuracy: 0.9663 - val_loss: 0.4206 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 248/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1562 - accuracy: 0.9664 - val_loss: 0.4204 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 249/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9665 - val_loss: 0.4204 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 250/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1560 - accuracy: 0.9663 - val_loss: 0.4202 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 251/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1559 - accuracy: 0.9668 - val_loss: 0.4200 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 252/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1559 - accuracy: 0.9665 - val_loss: 0.4203 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 253/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1557 - accuracy: 0.9665 - val_loss: 0.4202 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 254/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1557 - accuracy: 0.9664 - val_loss: 0.4200 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 255/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1556 - accuracy: 0.9665 - val_loss: 0.4197 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 256/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1556 - accuracy: 0.9665 - val_loss: 0.4196 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 257/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9667 - val_loss: 0.4203 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 258/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1554 - accuracy: 0.9665 - val_loss: 0.4198 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 259/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1552 - accuracy: 0.9667 - val_loss: 0.4200 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 260/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1552 - accuracy: 0.9665 - val_loss: 0.4195 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 261/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1551 - accuracy: 0.9665 - val_loss: 0.4192 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 262/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1550 - accuracy: 0.9665 - val_loss: 0.4196 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 263/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1549 - accuracy: 0.9667 - val_loss: 0.4195 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 264/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1549 - accuracy: 0.9665 - val_loss: 0.4194 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 265/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1547 - accuracy: 0.9663 - val_loss: 0.4192 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 266/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1547 - accuracy: 0.9669 - val_loss: 0.4191 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 267/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1546 - accuracy: 0.9666 - val_loss: 0.4192 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 268/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1545 - accuracy: 0.9663 - val_loss: 0.4189 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 269/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1544 - accuracy: 0.9667 - val_loss: 0.4186 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 270/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1543 - accuracy: 0.9666 - val_loss: 0.4187 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 271/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1542 - accuracy: 0.9665 - val_loss: 0.4191 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 272/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1541 - accuracy: 0.9671 - val_loss: 0.4192 - val_accuracy: 0.8800 - lr: 1.0000e-05\n",
            "Epoch 273/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1540 - accuracy: 0.9672 - val_loss: 0.4189 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 274/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1539 - accuracy: 0.9668 - val_loss: 0.4188 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 275/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1538 - accuracy: 0.9676 - val_loss: 0.4186 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 276/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1538 - accuracy: 0.9667 - val_loss: 0.4184 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 277/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1537 - accuracy: 0.9669 - val_loss: 0.4186 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 278/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1536 - accuracy: 0.9672 - val_loss: 0.4183 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 279/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1536 - accuracy: 0.9672 - val_loss: 0.4185 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 280/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9673 - val_loss: 0.4186 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 281/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1534 - accuracy: 0.9670 - val_loss: 0.4182 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 282/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1533 - accuracy: 0.9671 - val_loss: 0.4180 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 283/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1532 - accuracy: 0.9674 - val_loss: 0.4180 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 284/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1531 - accuracy: 0.9669 - val_loss: 0.4180 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 285/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1530 - accuracy: 0.9674 - val_loss: 0.4178 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 286/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1528 - accuracy: 0.9673 - val_loss: 0.4181 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 287/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1528 - accuracy: 0.9665 - val_loss: 0.4182 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 288/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1528 - accuracy: 0.9674 - val_loss: 0.4178 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 289/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1527 - accuracy: 0.9676 - val_loss: 0.4175 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 290/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1526 - accuracy: 0.9666 - val_loss: 0.4175 - val_accuracy: 0.8794 - lr: 1.0000e-05\n",
            "Epoch 291/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1525 - accuracy: 0.9672 - val_loss: 0.4175 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 292/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1525 - accuracy: 0.9674 - val_loss: 0.4172 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 293/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1524 - accuracy: 0.9678 - val_loss: 0.4172 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 294/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1523 - accuracy: 0.9678 - val_loss: 0.4171 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 295/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1522 - accuracy: 0.9672 - val_loss: 0.4173 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 296/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1521 - accuracy: 0.9678 - val_loss: 0.4170 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 297/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1520 - accuracy: 0.9674 - val_loss: 0.4169 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 298/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9675 - val_loss: 0.4169 - val_accuracy: 0.8806 - lr: 1.0000e-05\n",
            "Epoch 299/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1519 - accuracy: 0.9679 - val_loss: 0.4169 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 300/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1518 - accuracy: 0.9672 - val_loss: 0.4164 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 301/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1516 - accuracy: 0.9673 - val_loss: 0.4161 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 302/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9672 - val_loss: 0.4164 - val_accuracy: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 303/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9670 - val_loss: 0.4168 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 304/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9676 - val_loss: 0.4164 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 305/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1513 - accuracy: 0.9678 - val_loss: 0.4161 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 306/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1512 - accuracy: 0.9673 - val_loss: 0.4161 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 307/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1511 - accuracy: 0.9674 - val_loss: 0.4159 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 308/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1511 - accuracy: 0.9676 - val_loss: 0.4160 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 309/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1510 - accuracy: 0.9680 - val_loss: 0.4154 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 310/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1510 - accuracy: 0.9675 - val_loss: 0.4154 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 311/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9680 - val_loss: 0.4155 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 312/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1507 - accuracy: 0.9676 - val_loss: 0.4154 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 313/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1507 - accuracy: 0.9681 - val_loss: 0.4152 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 314/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1506 - accuracy: 0.9681 - val_loss: 0.4155 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 315/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1505 - accuracy: 0.9674 - val_loss: 0.4155 - val_accuracy: 0.8819 - lr: 1.0000e-05\n",
            "Epoch 316/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1504 - accuracy: 0.9678 - val_loss: 0.4153 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 317/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1502 - accuracy: 0.9683 - val_loss: 0.4153 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 318/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1502 - accuracy: 0.9680 - val_loss: 0.4148 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 319/500\n",
            "144/144 [==============================] - 2s 16ms/step - loss: 0.1501 - accuracy: 0.9681 - val_loss: 0.4147 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 320/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1501 - accuracy: 0.9679 - val_loss: 0.4151 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 321/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1500 - accuracy: 0.9678 - val_loss: 0.4147 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 322/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1500 - accuracy: 0.9681 - val_loss: 0.4143 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 323/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1498 - accuracy: 0.9679 - val_loss: 0.4147 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 324/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1498 - accuracy: 0.9678 - val_loss: 0.4145 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 325/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1496 - accuracy: 0.9683 - val_loss: 0.4140 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 326/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1495 - accuracy: 0.9677 - val_loss: 0.4144 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 327/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1495 - accuracy: 0.9682 - val_loss: 0.4142 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 328/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9683 - val_loss: 0.4140 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 329/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9676 - val_loss: 0.4142 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 330/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1493 - accuracy: 0.9678 - val_loss: 0.4139 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 331/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1491 - accuracy: 0.9682 - val_loss: 0.4137 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 332/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1491 - accuracy: 0.9676 - val_loss: 0.4137 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 333/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9688 - val_loss: 0.4136 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 334/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1490 - accuracy: 0.9688 - val_loss: 0.4136 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 335/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1489 - accuracy: 0.9681 - val_loss: 0.4134 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 336/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9681 - val_loss: 0.4134 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 337/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1488 - accuracy: 0.9685 - val_loss: 0.4134 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 338/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1486 - accuracy: 0.9684 - val_loss: 0.4132 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 339/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1485 - accuracy: 0.9684 - val_loss: 0.4129 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 340/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1484 - accuracy: 0.9684 - val_loss: 0.4132 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 341/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1484 - accuracy: 0.9683 - val_loss: 0.4130 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 342/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1483 - accuracy: 0.9685 - val_loss: 0.4129 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 343/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1482 - accuracy: 0.9683 - val_loss: 0.4131 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 344/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1481 - accuracy: 0.9684 - val_loss: 0.4127 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 345/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1480 - accuracy: 0.9687 - val_loss: 0.4127 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 346/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1480 - accuracy: 0.9685 - val_loss: 0.4126 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 347/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1479 - accuracy: 0.9685 - val_loss: 0.4126 - val_accuracy: 0.8825 - lr: 1.0000e-05\n",
            "Epoch 348/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1478 - accuracy: 0.9685 - val_loss: 0.4127 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 349/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1478 - accuracy: 0.9685 - val_loss: 0.4125 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 350/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9685 - val_loss: 0.4126 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 351/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1475 - accuracy: 0.9691 - val_loss: 0.4122 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 352/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1475 - accuracy: 0.9683 - val_loss: 0.4126 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 353/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1474 - accuracy: 0.9683 - val_loss: 0.4123 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 354/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1473 - accuracy: 0.9686 - val_loss: 0.4118 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 355/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1472 - accuracy: 0.9690 - val_loss: 0.4120 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 356/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1472 - accuracy: 0.9687 - val_loss: 0.4120 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 357/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9682 - val_loss: 0.4119 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 358/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9690 - val_loss: 0.4121 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 359/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1469 - accuracy: 0.9690 - val_loss: 0.4122 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 360/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1468 - accuracy: 0.9686 - val_loss: 0.4115 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 361/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1467 - accuracy: 0.9690 - val_loss: 0.4115 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 362/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1467 - accuracy: 0.9683 - val_loss: 0.4114 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 363/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1466 - accuracy: 0.9688 - val_loss: 0.4117 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 364/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1466 - accuracy: 0.9692 - val_loss: 0.4113 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 365/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1465 - accuracy: 0.9683 - val_loss: 0.4114 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 366/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1463 - accuracy: 0.9690 - val_loss: 0.4113 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 367/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1463 - accuracy: 0.9690 - val_loss: 0.4112 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 368/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1462 - accuracy: 0.9688 - val_loss: 0.4112 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 369/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1461 - accuracy: 0.9690 - val_loss: 0.4111 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 370/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1460 - accuracy: 0.9685 - val_loss: 0.4106 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 371/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1459 - accuracy: 0.9694 - val_loss: 0.4106 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 372/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1459 - accuracy: 0.9685 - val_loss: 0.4108 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 373/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1457 - accuracy: 0.9697 - val_loss: 0.4107 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 374/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1457 - accuracy: 0.9692 - val_loss: 0.4106 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 375/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1457 - accuracy: 0.9687 - val_loss: 0.4106 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 376/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1456 - accuracy: 0.9690 - val_loss: 0.4109 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 377/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1454 - accuracy: 0.9691 - val_loss: 0.4110 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 378/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1454 - accuracy: 0.9690 - val_loss: 0.4106 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 379/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1454 - accuracy: 0.9691 - val_loss: 0.4104 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 380/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1452 - accuracy: 0.9696 - val_loss: 0.4102 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 381/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1453 - accuracy: 0.9697 - val_loss: 0.4102 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 382/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1451 - accuracy: 0.9690 - val_loss: 0.4102 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 383/500\n",
            "144/144 [==============================] - 2s 16ms/step - loss: 0.1450 - accuracy: 0.9690 - val_loss: 0.4103 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 384/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1450 - accuracy: 0.9699 - val_loss: 0.4094 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 385/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1449 - accuracy: 0.9692 - val_loss: 0.4099 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 386/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1447 - accuracy: 0.9699 - val_loss: 0.4098 - val_accuracy: 0.8831 - lr: 1.0000e-05\n",
            "Epoch 387/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1447 - accuracy: 0.9695 - val_loss: 0.4099 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 388/500\n",
            "144/144 [==============================] - 2s 15ms/step - loss: 0.1446 - accuracy: 0.9692 - val_loss: 0.4096 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 389/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1445 - accuracy: 0.9694 - val_loss: 0.4094 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 390/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1445 - accuracy: 0.9694 - val_loss: 0.4096 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 391/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1444 - accuracy: 0.9699 - val_loss: 0.4097 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 392/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1443 - accuracy: 0.9692 - val_loss: 0.4096 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 393/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1443 - accuracy: 0.9694 - val_loss: 0.4096 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 394/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1442 - accuracy: 0.9694 - val_loss: 0.4096 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 395/500\n",
            "144/144 [==============================] - 3s 18ms/step - loss: 0.1441 - accuracy: 0.9694 - val_loss: 0.4095 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 396/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1440 - accuracy: 0.9700 - val_loss: 0.4091 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 397/500\n",
            "144/144 [==============================] - 2s 14ms/step - loss: 0.1439 - accuracy: 0.9697 - val_loss: 0.4091 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 398/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1439 - accuracy: 0.9697 - val_loss: 0.4093 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 399/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1437 - accuracy: 0.9692 - val_loss: 0.4091 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 400/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1437 - accuracy: 0.9696 - val_loss: 0.4092 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 401/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1437 - accuracy: 0.9693 - val_loss: 0.4089 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 402/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1435 - accuracy: 0.9697 - val_loss: 0.4087 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 403/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1435 - accuracy: 0.9695 - val_loss: 0.4089 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 404/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1434 - accuracy: 0.9699 - val_loss: 0.4086 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 405/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1432 - accuracy: 0.9697 - val_loss: 0.4086 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 406/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1432 - accuracy: 0.9693 - val_loss: 0.4089 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 407/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1432 - accuracy: 0.9697 - val_loss: 0.4085 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 408/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1431 - accuracy: 0.9694 - val_loss: 0.4087 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 409/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1430 - accuracy: 0.9701 - val_loss: 0.4085 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 410/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1429 - accuracy: 0.9701 - val_loss: 0.4083 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 411/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1428 - accuracy: 0.9698 - val_loss: 0.4081 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 412/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1427 - accuracy: 0.9698 - val_loss: 0.4082 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 413/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1427 - accuracy: 0.9701 - val_loss: 0.4079 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 414/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1426 - accuracy: 0.9698 - val_loss: 0.4081 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 415/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1426 - accuracy: 0.9700 - val_loss: 0.4077 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 416/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1425 - accuracy: 0.9700 - val_loss: 0.4081 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 417/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1424 - accuracy: 0.9697 - val_loss: 0.4077 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 418/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1423 - accuracy: 0.9695 - val_loss: 0.4076 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 419/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1423 - accuracy: 0.9701 - val_loss: 0.4080 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 420/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1421 - accuracy: 0.9701 - val_loss: 0.4077 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 421/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1422 - accuracy: 0.9698 - val_loss: 0.4078 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 422/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1420 - accuracy: 0.9697 - val_loss: 0.4073 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 423/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1420 - accuracy: 0.9700 - val_loss: 0.4071 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 424/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1418 - accuracy: 0.9700 - val_loss: 0.4073 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 425/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1418 - accuracy: 0.9704 - val_loss: 0.4070 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 426/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1418 - accuracy: 0.9699 - val_loss: 0.4068 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 427/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1417 - accuracy: 0.9697 - val_loss: 0.4071 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 428/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1415 - accuracy: 0.9705 - val_loss: 0.4068 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 429/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1415 - accuracy: 0.9699 - val_loss: 0.4073 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 430/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1415 - accuracy: 0.9700 - val_loss: 0.4068 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 431/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1414 - accuracy: 0.9701 - val_loss: 0.4065 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 432/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1412 - accuracy: 0.9701 - val_loss: 0.4066 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 433/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1411 - accuracy: 0.9699 - val_loss: 0.4064 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 434/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1411 - accuracy: 0.9703 - val_loss: 0.4064 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 435/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1410 - accuracy: 0.9702 - val_loss: 0.4062 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 436/500\n",
            "144/144 [==============================] - 2s 12ms/step - loss: 0.1410 - accuracy: 0.9706 - val_loss: 0.4065 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 437/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1408 - accuracy: 0.9703 - val_loss: 0.4063 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 438/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1408 - accuracy: 0.9706 - val_loss: 0.4062 - val_accuracy: 0.8875 - lr: 1.0000e-05\n",
            "Epoch 439/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1407 - accuracy: 0.9702 - val_loss: 0.4061 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 440/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1407 - accuracy: 0.9703 - val_loss: 0.4059 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 441/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1406 - accuracy: 0.9699 - val_loss: 0.4063 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 442/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1405 - accuracy: 0.9703 - val_loss: 0.4058 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 443/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1404 - accuracy: 0.9706 - val_loss: 0.4061 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 444/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1404 - accuracy: 0.9705 - val_loss: 0.4060 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 445/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1403 - accuracy: 0.9708 - val_loss: 0.4062 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 446/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9711 - val_loss: 0.4056 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 447/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9709 - val_loss: 0.4058 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 448/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1401 - accuracy: 0.9706 - val_loss: 0.4054 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 449/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1401 - accuracy: 0.9703 - val_loss: 0.4054 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 450/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1399 - accuracy: 0.9708 - val_loss: 0.4059 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 451/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1399 - accuracy: 0.9705 - val_loss: 0.4055 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 452/500\n",
            "144/144 [==============================] - 2s 13ms/step - loss: 0.1398 - accuracy: 0.9708 - val_loss: 0.4054 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 453/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1397 - accuracy: 0.9702 - val_loss: 0.4055 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 454/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1396 - accuracy: 0.9708 - val_loss: 0.4054 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 455/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1395 - accuracy: 0.9704 - val_loss: 0.4053 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 456/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1395 - accuracy: 0.9705 - val_loss: 0.4051 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 457/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1395 - accuracy: 0.9708 - val_loss: 0.4051 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 458/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1393 - accuracy: 0.9707 - val_loss: 0.4048 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 459/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1393 - accuracy: 0.9709 - val_loss: 0.4053 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 460/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1392 - accuracy: 0.9709 - val_loss: 0.4049 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 461/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1392 - accuracy: 0.9704 - val_loss: 0.4050 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 462/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1389 - accuracy: 0.9712 - val_loss: 0.4048 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 463/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1390 - accuracy: 0.9703 - val_loss: 0.4053 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 464/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1389 - accuracy: 0.9710 - val_loss: 0.4050 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 465/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1388 - accuracy: 0.9714 - val_loss: 0.4045 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 466/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1388 - accuracy: 0.9707 - val_loss: 0.4044 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 467/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1386 - accuracy: 0.9708 - val_loss: 0.4045 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 468/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1386 - accuracy: 0.9706 - val_loss: 0.4042 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 469/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1386 - accuracy: 0.9709 - val_loss: 0.4043 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 470/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1384 - accuracy: 0.9711 - val_loss: 0.4043 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 471/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9704 - val_loss: 0.4042 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 472/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1383 - accuracy: 0.9710 - val_loss: 0.4041 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 473/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1382 - accuracy: 0.9711 - val_loss: 0.4038 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 474/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1383 - accuracy: 0.9706 - val_loss: 0.4038 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 475/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1381 - accuracy: 0.9715 - val_loss: 0.4037 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 476/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1381 - accuracy: 0.9710 - val_loss: 0.4041 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 477/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1380 - accuracy: 0.9711 - val_loss: 0.4037 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 478/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1379 - accuracy: 0.9706 - val_loss: 0.4040 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 479/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1378 - accuracy: 0.9711 - val_loss: 0.4037 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 480/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1377 - accuracy: 0.9710 - val_loss: 0.4039 - val_accuracy: 0.8881 - lr: 1.0000e-05\n",
            "Epoch 481/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1377 - accuracy: 0.9708 - val_loss: 0.4033 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 482/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1376 - accuracy: 0.9713 - val_loss: 0.4039 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 483/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1375 - accuracy: 0.9715 - val_loss: 0.4036 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 484/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1374 - accuracy: 0.9711 - val_loss: 0.4033 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 485/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1374 - accuracy: 0.9713 - val_loss: 0.4035 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 486/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1374 - accuracy: 0.9711 - val_loss: 0.4034 - val_accuracy: 0.8875 - lr: 1.0000e-05\n",
            "Epoch 487/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1373 - accuracy: 0.9718 - val_loss: 0.4035 - val_accuracy: 0.8838 - lr: 1.0000e-05\n",
            "Epoch 488/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1371 - accuracy: 0.9713 - val_loss: 0.4037 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 489/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1371 - accuracy: 0.9715 - val_loss: 0.4032 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 490/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1372 - accuracy: 0.9710 - val_loss: 0.4029 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 491/500\n",
            "144/144 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.9718 - val_loss: 0.4027 - val_accuracy: 0.8875 - lr: 1.0000e-05\n",
            "Epoch 492/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1369 - accuracy: 0.9711 - val_loss: 0.4027 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 493/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1368 - accuracy: 0.9713 - val_loss: 0.4029 - val_accuracy: 0.8875 - lr: 1.0000e-05\n",
            "Epoch 494/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1367 - accuracy: 0.9710 - val_loss: 0.4028 - val_accuracy: 0.8856 - lr: 1.0000e-05\n",
            "Epoch 495/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1366 - accuracy: 0.9711 - val_loss: 0.4028 - val_accuracy: 0.8850 - lr: 1.0000e-05\n",
            "Epoch 496/500\n",
            "144/144 [==============================] - 2s 10ms/step - loss: 0.1366 - accuracy: 0.9710 - val_loss: 0.4030 - val_accuracy: 0.8863 - lr: 1.0000e-05\n",
            "Epoch 497/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1365 - accuracy: 0.9712 - val_loss: 0.4031 - val_accuracy: 0.8844 - lr: 1.0000e-05\n",
            "Epoch 498/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1364 - accuracy: 0.9717 - val_loss: 0.4026 - val_accuracy: 0.8881 - lr: 1.0000e-05\n",
            "Epoch 499/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1365 - accuracy: 0.9710 - val_loss: 0.4027 - val_accuracy: 0.8869 - lr: 1.0000e-05\n",
            "Epoch 500/500\n",
            "144/144 [==============================] - 2s 11ms/step - loss: 0.1364 - accuracy: 0.9719 - val_loss: 0.4025 - val_accuracy: 0.8875 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Model Accuracy"
      ],
      "metadata": {
        "id": "g7odyA0YMOl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,6))\n",
        "ax2.plot(history.history['loss'], color='orange', label='Loss')\n",
        "ax2.plot(history.history['val_loss'], color='blue', label='val_loss')\n",
        "ax2.legend(loc='upper right')\n",
        "ax1.plot(history.history['accuracy'], label='Accuracy', color='orange')\n",
        "ax1.plot(history.history['val_accuracy'], label='val_accuracy', color='blue')\n",
        "ax1.legend(loc=\"upper right\")\n",
        "ax1.set_title(\"Model-Accuracy w.r.t Epochs\", loc='center')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "baPyqOECaBN1",
        "outputId": "dd36d895-8174-422a-d77e-a3350795b2fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(np.array(X_test).reshape(1600, 1,20))"
      ],
      "metadata": {
        "trusted": true,
        "id": "G80_6yuJaBN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866b4edb-cbcf-4056-f086-40a5d991a3fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_classes = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "v6EQM3VxaBN1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_classes"
      ],
      "metadata": {
        "trusted": true,
        "id": "VG8UsH1LaBN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400f461d-5f77-485c-9fe5-73f57da06ec1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36, 39, 39, ..., 41,  2, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}